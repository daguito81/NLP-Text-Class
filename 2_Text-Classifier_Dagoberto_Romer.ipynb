{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Assignment 2 - Text Classification\n",
    "**Dagoberto Romer**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import jtplot module in notebook\n",
    "from jupyterthemes import jtplot\n",
    "# choose which theme to inherit plotting style from\n",
    "# onedork | grade3 | oceans16 | chesterish | monokai | solarizedl | solarizedd\n",
    "jtplot.style(theme='gruvboxd')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Text Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_script = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The folder \"unsup\" inside the train folder was deleted as those are not labeled. Becuase we're working on windos and to avoid unsupported commands, we removed the folder manually"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the `load_files()` function in sklearn as it already reads the folder structure as is and assigns targets depending on the name of the folders, pos = 1 and neg = 0.  \n",
    "We also use `load_content=True` and encoding utf8 so it reads it as a String instead of a Byte so we can use feature extraction classes in sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** This text loading function might take a few minutes, I suspect it has to do with the Windows Defender as its CPU usage shoots up as well. I can only guess that it's scanning every file as it loads. On my Desktop it takes about 3 minutes to load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_train = load_files(\"./aclImdb/train/\", load_content=True,\n",
    "                           encoding='utf8', categories=['pos', 'neg'])\n",
    "reviews_test = load_files(\"./aclImdb/test/\", load_content=True,\n",
    "                          encoding='utf8', categories=['pos', 'neg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.DataFrame(reviews_train.data, columns=['review'])\n",
    "train['sentiment'] = reviews_train.target\n",
    "test = pd.DataFrame(reviews_test.data, columns=['review'])\n",
    "test['sentiment'] = reviews_test.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Zero Day leads you to think, even re-think why...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Words can't describe how bad this movie is. I ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Everyone plays their part pretty well in this ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>There are a lot of highly talented filmmakers/...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I've just had the evidence that confirmed my s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  Zero Day leads you to think, even re-think why...          1\n",
       "1  Words can't describe how bad this movie is. I ...          0\n",
       "2  Everyone plays their part pretty well in this ...          1\n",
       "3  There are a lot of highly talented filmmakers/...          0\n",
       "4  I've just had the evidence that confirmed my s...          0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Don't hate Heather Graham because she's beauti...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I don't know how this movie has received so ma...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I caught this movie on the Horror Channel and ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NBC had a chance to make a powerful religious ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Looking for something shocking? Okay fine... t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  Don't hate Heather Graham because she's beauti...          1\n",
       "1  I don't know how this movie has received so ma...          0\n",
       "2  I caught this movie on the Horror Channel and ...          1\n",
       "3  NBC had a chance to make a powerful religious ...          0\n",
       "4  Looking for something shocking? Okay fine... t...          0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a DataFrame for each train and test sets. Consisting fo 2 columns, text and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 25000 entries, 0 to 24999\n",
      "Data columns (total 2 columns):\n",
      "review       25000 non-null object\n",
      "sentiment    25000 non-null int32\n",
      "dtypes: int32(1), object(1)\n",
      "memory usage: 293.0+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 25000 entries, 0 to 24999\n",
      "Data columns (total 2 columns):\n",
      "review       25000 non-null object\n",
      "sentiment    25000 non-null int32\n",
      "dtypes: int32(1), object(1)\n",
      "memory usage: 293.0+ KB\n"
     ]
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each set has 25000 entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentiment</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           review\n",
       "sentiment        \n",
       "0           12500\n",
       "1           12500"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.groupby('sentiment').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentiment</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           review\n",
       "sentiment        \n",
       "0           12500\n",
       "1           12500"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.groupby('sentiment').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each set is equally divided by 50% bad sentiment (0) and good sentiment (1).  \n",
    "We can then use accuracy as our main metric as there is no inbalance in the set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Quality Issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know that we have some html breaks as `<br />` that we can replace with regular spaces.  \n",
    "We also have some punctuations, numbers and single character words that don't provide any additional information so we want to remove them.  \n",
    "We create a function we can pass through the Dataframe so we can apply it to every review. As we will use replace to take out the breaks. we will run 2 different applies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_line(line):\n",
    "    # split into tokens by white space\n",
    "    tokens = line.split()\n",
    "    # remove punctuation from each token\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    tokens = [w.translate(table) for w in tokens]\n",
    "    # remove remaining tokens that are not alphabetic\n",
    "    tokens = [word for word in tokens if word.isalpha()]\n",
    "    # filter out short tokens\n",
    "    tokens = [word for word in tokens if len(word) > 1]\n",
    "    line = \" \".join(tokens)\n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Set:\n",
    "train['review'] = train['review'].apply(lambda x: x.replace(\"<br />\", \" \"))\n",
    "train['review'] = train['review'].apply(lambda line: clean_line(line))\n",
    "\n",
    "# Test Set\n",
    "test['review'] = test['review'].apply(lambda x: x.replace(\"<br />\", \" \"))\n",
    "test['review'] = test['review'].apply(lambda line: clean_line(line))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center"
   },
   "source": [
    "We check the text of one review we knew it contained a break and \"sub-par\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "cell_style": "center"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Movie was subpar but this Television Pilot delivers great springboard into what has become SciFi fans Ideal program The Actors deliver and the special effects for television series are spectacular Having an intelligent interesting script doesnt hurt either Stargate is currently one of my favorite programs'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.iloc[5]['review']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### X/y Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we split our Data into features and targets, Text Feature functions like CountVectorizer and TfidfVectorizer require the text to be set as a list of document instead of a dataframe or a pd.Series. So we will change our data to match that accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train['review'].tolist()\n",
    "y_train = train['sentiment']\n",
    "X_test = test['review'].tolist()\n",
    "y_test = test['sentiment']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use either CountVectorizer or TfidfVectorizer:  \n",
    " - CountVectorizer simply counts ever 2 or more letter word, all in lowercase and split by any word boundaries\n",
    " - TFIDF calculates the Term Frecuency and Inverse Document Frecuency, giving less importance to words that appear in every document (words that are very common and not representative)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another thing that's useful is to remove stopwords in our set. This is basically removing words that are so common in the language that they provide basically no information for text analysis.  \n",
    "Lastly we set a minimum appeareance of 5 to remove all words that were mispelled or particular to only 1 document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We'll start using the simpler `CountVectorizer()`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(min_df=5, stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=5,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<25000x28001 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 2102670 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_X_train = vect.transform(X_train)\n",
    "new_X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives us a sparse matrix if 25000 rows by almost 27k features. If we had left the `min_df=1` and the stopwords, this would've been more than 70k features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_ml_basic = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we have a very wide sparse matrix where features > rows, a linear model is our best bet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Cross Validation Accuracy: 0.87\n"
     ]
    }
   ],
   "source": [
    "cv_scores = cross_val_score(lr_model, new_X_train, y_train, cv=10, n_jobs=-1)\n",
    "print(\"Mean Cross Validation Accuracy: {}\".format(round(np.mean(cv_scores), 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also try to optimize the model by gridsearching for the C parameter in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(LogisticRegression(),\n",
    "                    param_grid=param_grid, cv=5, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best CV Score: 0.88192\n",
      "Best Parameters: {'C': 0.1}\n"
     ]
    }
   ],
   "source": [
    "grid.fit(new_X_train, y_train)\n",
    "print(\"Best CV Score: {}\".format(grid.best_score_))\n",
    "print(\"Best Parameters: {}\".format(grid.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_C</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.84228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.87628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.88192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.87280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>0.86548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100</td>\n",
       "      <td>0.86036</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  param_C  mean_test_score\n",
       "0   0.001          0.84228\n",
       "1    0.01          0.87628\n",
       "2     0.1          0.88192\n",
       "3       1          0.87280\n",
       "4      10          0.86548\n",
       "5     100          0.86036"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid.cv_results_).loc[:, ['param_C', 'mean_test_score']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also test our data against the test set (transformed by the same vectorizer) to make sure our model is able to generalize with new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the same vectorizer to have the same features\n",
    "new_X_test = vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87344"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.score(new_X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The score is fairly close to our Cross Validation Score. So our model is generalizing well"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_ml_adv = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the 1st advanced model we will use:  \n",
    " - NLTK Stopwords\n",
    " - Lemmatization (commented out because of time requirements)\n",
    " - TFIDF\n",
    " - Up to 3 words ngrams\n",
    " - Model Tuning using Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Dagoberto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Dagoberto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from nltk import WordNetLemmatizer as wnl\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "stopwords = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will reprocess the data to do lemmatization. This process can take a couple of minutes to run:  \n",
    " - Lemmatization works by transforming the word into it's lemma. This is based on using WordNet's morphy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "foot\n",
      "hanging\n"
     ]
    }
   ],
   "source": [
    "# Lemmatization Example\n",
    "word = 'feet'\n",
    "print(wnl().lemmatize(word))\n",
    "print(wnl().lemmatize('hanging'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Potential problem:**  \n",
    "We have some words that can have different meanings. So we need to specify the Part of Speech part to the lemmatizer if we want to correctly lemmatize the words, if they are verbs or nouns, etc. In our example, hanging was kept as hanging because we didn't specify it was a verb.  The package we're using allows us to do that but Spacy allows us to do it much easier and faster\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** If you want to run the spacy lemmatization you might not be able to run the Convolutional Neural Network and the LSTM. After testing, the lemmatization also didn't have any improvement on the scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import spacy\n",
    "# nlp = spacy.load('en', disable=['parser', 'ner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create a lemmatizer function here\n",
    "# def lemmatizer_spacy(line):\n",
    "#    doc = nlp(line)\n",
    "#    line = \" \".join([token.lemma_ for token in doc])\n",
    "#    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing\n",
    "# line = \"We are running from hanging hangers because you and I are not here\"\n",
    "# lemmatizer_spacy(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our nonsensical example, we can see how it differentiates hanging as  a verb, and hangers as the plural of hanger and pronouns are just -PRON-  and are turns into be. So we will use this on our files and see if it makes it better.  \n",
    "**Note:** As this will take a long time to train, we will do it separately instead of in the pipeline so it doesn't run every time (on my desktop this next cell takes 8 minutes to complete)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lemmatization takes over 8 minutes to run and it didn't improve any of our models. We leave it commented as to be able to run the entire notebook faster. If you want to run lemmatization, uncomment the next 2 lines in the cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train['review'] = train['review'].apply(lambda x: lemmatizer_spacy(x))\n",
    "# test['review'] = test['review'].apply(lambda x: lemmatizer_spacy(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train['review'].tolist()\n",
    "y_train = train['sentiment']\n",
    "X_test = test['review'].tolist()\n",
    "y_test = test['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_adv_preprocess = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a pipeline that will grab our processed data thgouhg a TFIDF Vectorizer and then into a Logistic Regression model (because of the ease and speed, we have more complicated models later on)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = make_pipeline(TfidfVectorizer(\n",
    "    min_df=5, stop_words=stopwords), LogisticRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'tfidfvectorizer__ngram_range': [(1, 2), (1, 3), (1, 4)],\n",
    "    'logisticregression__C': [5, 10, 15]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(pipe, param_grid=param_grid, n_jobs=-1, cv=3, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  27 out of  27 | elapsed:  4.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('tfidfvectorizer', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=5,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth...penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False))]),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'tfidfvectorizer__ngram_range': [(1, 2), (1, 3), (1, 4)], 'logisticregression__C': [5, 10, 15]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'logisticregression__C': 10, 'tfidfvectorizer__ngram_range': (1, 3)}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.89492"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get 89.4% accuracy with this model, using (1, 3) ngram range and a C of 10.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(grid.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_table = results.pivot_table(\n",
    "    'mean_test_score', 'param_tfidfvectorizer__ngram_range', 'param_logisticregression__C')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x16e1727e6d8>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 460.8x403.2 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(res_table, annot=True, fmt=\".3f\", cmap=\"viridis\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Cross Validation Accuracy: 0.89\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean Cross Validation Accuracy: {}\".format(round(grid.best_score_, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score Accuracy: 0.89\n"
     ]
    }
   ],
   "source": [
    "print(\"Test Score Accuracy: {}\".format(round(grid.score(X_test, y_test), 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The numbers are really close to each other so the model is also generalizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_ml_nb = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes was used a lot in spam detection filters, so it makes sense to use it for sentiment analysis as it's a binary classification problem from the words in the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.base import TransformerMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseTransformer(TransformerMixin):\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None, **fit_params):\n",
    "        return X.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = make_pipeline(TfidfVectorizer(\n",
    "    min_df=5, stop_words=stopwords, ngram_range=(1, 1), ), DenseTransformer(), GaussianNB())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These 2 lines are commented because Naive Bayes requires the matrix to be dense which will increase the memory footprint by a LOT. And the score is not even close to using Log Reg. So we leave it commented. Also we run into Memory Errors when we try more than 1,1 ngrams. So we have to keep it at 1,1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipe.score(X_test, y_test)\n",
    "# 0.6288"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The score is MUCH worse than using Logistic Regression and the memory footprint to do this was huge in comparison so there is no reason to pursue this model further"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SUPER Advanced Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For these models we're using Tensorflow and Keras as its high level API to build, train and test the models. We're going to use 3 different approaches to see if they are any better than a simple logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These models we're trained using a GTX1070 to speed up the process. Beware of running these cells with a laptop. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this Model we will use Neural networks\n",
    " - Dense Neural network\n",
    " - Convolutional Neural network\n",
    " - LSTM Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From our previous experiments, we can see that (1,3) ngram was the best, but it will also increse our features substantially. As we already know 1 epoch of (1, 1) ngrams will take about 12 seconds with a GPU, we go ahead and do it for (1, 3).  \n",
    "*Note*: We tried with (1, 3) ngram range but the memory requirement is higher than what we have availabe and we get a Resource Exhausted error. So we keep it at (1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_vec = CountVectorizer(stop_words=stopwords, min_df=5, ngram_range=(1, 1))\n",
    "vec = TfidfVectorizer(stop_words=stopwords, min_df=5, ngram_range=(1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec.fit(X_train)  # We will try the tfidf vectorizer\n",
    "new_X_train = vec.transform(X_train)\n",
    "new_X_test = vec.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<25000x28178 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 2370371 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whenever we run the Dense neural network first, we run into a problem. might be realted to memory and resources as the DNN is the one with the most parameters to train. So we will run CNN then LSTM and DNN at the end "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_nn_cnn = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolutional Networks require the features to be in index form. Instead of a simple sparse matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12387, 25063]\n",
      "[28131, 6121, 14209, 25177, 8456, 20805, 26038, 15677, 27869, 4781, 16549, 24330, 26866, 22888, 4364, 3559, 16528, 2307, 2427, 16101, 26038, 12045, 6223, 27735, 4790, 4315, 17539, 6307, 27840, 26866, 5477, 6598, 18322, 16375, 10410, 9263, 220, 20496, 19356, 25031, 8681, 16335, 207, 26038, 28064, 2287, 7903, 25031, 9246, 10313, 22829, 8932, 8932, 2287, 9246, 686, 1045, 14469, 21996, 9441, 11848, 25037, 11850]\n"
     ]
    }
   ],
   "source": [
    "word2idx = {word: idx for idx, word in enumerate(vec.get_feature_names())}\n",
    "tokenize = vec.build_tokenizer()\n",
    "preprocess = vec.build_preprocessor()\n",
    "\n",
    "\n",
    "def to_sequence(tokenizer, preprocessor, index, text):\n",
    "    words = tokenizer(preprocessor(text))\n",
    "    indexes = [index[word] for word in words if word in index]\n",
    "    return indexes\n",
    "\n",
    "\n",
    "print(to_sequence(tokenize, preprocess, word2idx, \"This is an important test!\"))\n",
    "X_train_sequences = [to_sequence(\n",
    "    tokenize, preprocess, word2idx, x) for x in X_train]\n",
    "print(X_train_sequences[0])  # This shows the words that are on every line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAX_SEQ_LENGHT= 1290\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28178 28178 28178 ... 27840  2287 17413]\n"
     ]
    }
   ],
   "source": [
    "# Compute the max lenght of a text\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "MAX_SEQ_LENGHT = len(max(X_train_sequences, key=len))\n",
    "print(\"MAX_SEQ_LENGHT=\", MAX_SEQ_LENGHT)\n",
    "\n",
    "N_FEATURES = len(vec.get_feature_names())\n",
    "# This creates a padded sequence so every row has the same number of features\n",
    "X_train_sequences = pad_sequences(\n",
    "    X_train_sequences, maxlen=MAX_SEQ_LENGHT, value=N_FEATURES)\n",
    "print(X_train_sequences[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 1290)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_sequences.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that the maximum review we have had 1405 words. And it meant that it grabbed every row and made it have the same ammount of \"words\" by padding each sequence with a number which is the last value in our features (so it's still the inside the feature matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 1290, 64)          1803456   \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 1286, 64)          20544     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 257, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 16448)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                1052736   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 2,878,849\n",
      "Trainable params: 2,878,849\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, Embedding, Dropout\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(len(vec.get_feature_names()) + 1,\n",
    "                    64,  # Embedding Size\n",
    "                    input_length=MAX_SEQ_LENGHT))\n",
    "model.add(Conv1D(64, 5, activation='relu'))\n",
    "model.add(MaxPooling1D(5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      " - 6s - loss: 0.5006 - acc: 0.7111 - val_loss: 0.2984 - val_acc: 0.8774\n",
      "Epoch 2/5\n",
      " - 4s - loss: 0.1835 - acc: 0.9315 - val_loss: 0.2947 - val_acc: 0.8832\n",
      "Epoch 3/5\n",
      " - 4s - loss: 0.0698 - acc: 0.9788 - val_loss: 0.4075 - val_acc: 0.8760\n",
      "Epoch 4/5\n",
      " - 4s - loss: 0.0230 - acc: 0.9946 - val_loss: 0.5276 - val_acc: 0.8760\n",
      "Epoch 5/5\n",
      " - 4s - loss: 0.0065 - acc: 0.9988 - val_loss: 0.6275 - val_acc: 0.8760\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x16e25e2fef0>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_sequences[:-5000], y_train[:-5000],\n",
    "          epochs=5, batch_size=128, verbose=2,\n",
    "          validation_data=(X_train_sequences[-5000:], y_train[-5000:]),\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_sequences = [to_sequence(\n",
    "    tokenize, preprocess, word2idx, x) for x in X_test]\n",
    "X_test_sequences = pad_sequences(\n",
    "    X_test_sequences, maxlen=MAX_SEQ_LENGHT, value=N_FEATURES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 2s 77us/step\n",
      "Accuracy: 0.84992\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X_test_sequences, y_test)\n",
    "print(\"Accuracy: {}\".format(scores[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get slightly worse scores than the original Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dense Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_nn_dnn = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we create our first model. Based on 1 input, 1 hidden and 1 output dense layer. Activation function is rectified linear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 2000)              56358000  \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1000)              2001000   \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 1001      \n",
      "=================================================================\n",
      "Total params: 58,360,001\n",
      "Trainable params: 58,360,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(2000, activation='relu', input_dim=len(vec.get_feature_names())))\n",
    "model.add(Dense(1000, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we set our Train / Validation Set (this can done using SKLearn wrappers to make cross validation/grid search but we're so outside the scope at this point that prefered to do it this way "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      " - 14s - loss: 0.3308 - acc: 0.8590 - val_loss: 0.2731 - val_acc: 0.8868\n",
      "Epoch 2/5\n",
      " - 12s - loss: 0.0652 - acc: 0.9769 - val_loss: 0.4129 - val_acc: 0.8674\n",
      "Epoch 3/5\n",
      " - 12s - loss: 0.0087 - acc: 0.9972 - val_loss: 0.7014 - val_acc: 0.8658\n",
      "Epoch 4/5\n",
      " - 12s - loss: 7.0719e-04 - acc: 0.9999 - val_loss: 0.8288 - val_acc: 0.8682\n",
      "Epoch 5/5\n",
      " - 12s - loss: 1.2505e-04 - acc: 1.0000 - val_loss: 0.8931 - val_acc: 0.8672\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x16e1b8e9908>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(new_X_train[:-5000], y_train[:-5000], batch_size=128,\n",
    "          epochs=5, verbose=2, validation_data=(new_X_train[-5000:], y_test[-5000:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From doing 5 epochs we get a validation score around 87.5%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 6s 231us/step\n",
      "Accuracy: 0.84588\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(new_X_test, y_test)\n",
    "print(\"Accuracy: {}\".format(scores[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ALL THIS POWER AND IT DIDNT EVEN GET A BETTER SCORE!!!!\n",
    "\n",
    "We got 87% on Validation and about 83% on Test scores. It was better to just use logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTM Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_nn_lstm = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly we will use a Recurrent Neural Network, known as Long Short Term Memory network. These are used a lot in sentiment analysis and natural language processing.  \n",
    "This also reuses the processing we did for the CNN. So no need to redo that "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 1290, 64)          1803456   \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_1 (CuDNNLSTM)     (None, 64)                33280     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 1,836,801\n",
      "Trainable params: 1,836,801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Embedding, CuDNNLSTM\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(len(vec.get_feature_names()) + 1,\n",
    "                    64,  # Embedding Size\n",
    "                    input_length=MAX_SEQ_LENGHT))\n",
    "model.add(CuDNNLSTM(64))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      " - 9s - loss: 0.5182 - acc: 0.7540 - val_loss: 0.3303 - val_acc: 0.8644\n",
      "Epoch 2/5\n",
      " - 9s - loss: 0.2135 - acc: 0.9202 - val_loss: 0.2988 - val_acc: 0.8718\n",
      "Epoch 3/5\n",
      " - 9s - loss: 0.1064 - acc: 0.9671 - val_loss: 0.3540 - val_acc: 0.8718\n",
      "Epoch 4/5\n",
      " - 9s - loss: 0.0559 - acc: 0.9846 - val_loss: 0.4628 - val_acc: 0.8670\n",
      "Epoch 5/5\n",
      " - 9s - loss: 0.0325 - acc: 0.9913 - val_loss: 0.6057 - val_acc: 0.8634\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x16e3f19fb00>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_sequences[:-5000], y_train[:-5000],\n",
    "          epochs=5, batch_size=128, verbose=2,\n",
    "          validation_data=(X_train_sequences[-5000:], y_train[-5000:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 14s 545us/step\n",
      "Accuracy: 0.84336\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X_test_sequences, y_test)\n",
    "print(\"Accuracy: {}\".format(scores[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am really dissapointed now..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_script = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the best model was our simpler and first model. We tried improving it by processing the text more, lemmatizing the words, created more complex pipelines and even different kinds of neural networks to try and get a better score. Without any success. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case it might be because we are not dealing with that many data points. Neural Nets get top flex their muscles when you start running millions and millions of rows through them. In this case it's really easy for the Neural net to overfit into the training data and then have a worse outcome on the validation / test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All results in minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Script: 8.594632323582967\n",
      "Data Processing: 0.29358097712198894\n",
      "Basic ML Model: 0.7495545625686646\n",
      "Lemmatization: 0.04672394990921021\n",
      "Adv ML Model: 5.357212221622467\n",
      "Dense Neural Network: 1.1299321850140889\n",
      "Convolutional Neural Network: 0.5373992363611857\n",
      "Long Short Term Memory Network: 1.0643523772557577\n"
     ]
    }
   ],
   "source": [
    "print(\"Total Script: {}\".format(\n",
    "    (stop_script - start_script) / 60))\n",
    "print(\"Data Processing: {}\".format(\n",
    "    (start_ml_basic - start_script) / 60))\n",
    "print(\"Basic ML Model: {}\".format(\n",
    "    (start_ml_adv - start_ml_basic) / 60))\n",
    "print(\"Lemmatization: {}\".format(\n",
    "    (stop_adv_preprocess - start_ml_adv) / 60))\n",
    "print(\"Adv ML Model: {}\".format(\n",
    "    (start_nn_dnn - start_ml_adv) / 60))\n",
    "print(\"Dense Neural Network: {}\".format(\n",
    "    (start_nn_lstm - start_nn_dnn) / 60))\n",
    "print(\"Convolutional Neural Network: {}\".format(\n",
    "    (start_nn_dnn - start_nn_cnn) / 60))\n",
    "print(\"Long Short Term Memory Network: {}\".format(\n",
    "    (stop_script - start_nn_lstm) / 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2046"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.clear_session()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:basicdata]",
   "language": "python",
   "name": "conda-env-basicdata-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "603px",
    "left": "36px",
    "top": "273px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
